{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f65c661c-8855-4ed2-838d-57c6f4afa723",
   "metadata": {},
   "source": [
    "# Memory in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2127d7-ec5c-445b-ac30-bb4a51246742",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- Memory management in Python\n",
    "    - Objects and addresses\n",
    "    - Object references\n",
    "    - Garbage collection\n",
    "- Monitor/observe memory usage\n",
    "    - Single line of code\n",
    "    - One function call\n",
    "- Handling memory-related issues\n",
    "    - Memory mapping\n",
    "    - General considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c19db-a775-431f-a33e-461d8cefbe10",
   "metadata": {},
   "source": [
    "# Memory management in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9431d303-46ff-4b48-893f-144ae4d09650",
   "metadata": {},
   "source": [
    "### Objects\n",
    "Classes, functions, and even simple data types, such as integers, floats, and strings, are represented as 'objects' in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bfacaf-e1f4-404e-b9ee-71977a77b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(\"empty dict: \", sys.getsizeof({}))\n",
    "print(\"empty list: \", sys.getsizeof([]))\n",
    "print(\"empty set: \", sys.getsizeof(set()))\n",
    "print(\"empty string: \", sys.getsizeof(\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90132df-341b-4ec6-a831-3cf4597f5f5a",
   "metadata": {},
   "source": [
    "Evidently, Python objects have a fixed overhead (in bytes, 1 byte = 8 bits) that varies from one object type to another. This overhead is needed to support dynamic numerical ranges (for example - int type does not have a limited range like C int has; the only limit is the available memory), the current size of the dynamic storage, and object bookkeeping such as a reference to the relevant object and a reference count."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d540da-b710-4812-9643-4419fafd8201",
   "metadata": {},
   "source": [
    "Check ASCII Table\n",
    "[ASCII Character](https://www.ascii-code.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bb96dc-0531-4068-ad25-328b9c782a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"BIOE-488\" # string of 8 characters\n",
    "sys.getsizeof(title) # 1 byte per character in string --> If ASCII"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d9eec5-524f-4a4c-a2c0-4a64f3217fea",
   "metadata": {},
   "source": [
    "An empty string takes 41 bytes, and each additional character adds another byte (41 + 8 = 49). That says a lot about the tradeoffs of keeping multiple short strings where you'll pay the 41 bytes overhead for each one vs. a single long string where you pay the overhead only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c90db-9eb7-4546-8d03-246478d9232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"BIOE-488\"+\"\\U0001F60A\"\n",
    "print(title)\n",
    "sys.getsizeof(title) # 4 byte per character in string --> If Unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95100d9-4ee6-4b39-9925-07728d7bc882",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = True # represented as integer 1\n",
    "b = False # represented as integer 0\n",
    "print(sys.getsizeof(True))\n",
    "print(sys.getsizeof(False))\n",
    "print(sys.getsizeof(a))\n",
    "print(sys.getsizeof(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edb39ac-4379-490e-ba72-2b775c765388",
   "metadata": {},
   "source": [
    "Booleans are stored as integers. An integer is represented by a sequence of 4-byte chunks. An empty integer object such as False/0 contains no filled chunks. As soon as you actually have an int value > 0, which is the case with True/1, the integer object's chunk array isn't empty anymore as one 4-byte chunk gets filled. Read more - https://stackoverflow.com/questions/49926843/why-is-a-false-value-0-smaller-in-bytes-than-true-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a5f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "a = 12313423342343234563434543453434636 # try to fill more chunks of the integer data array\n",
    "print(sys.getsizeof(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a6e75-e463-4650-9781-58289cd0b5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can import special datatytpes\n",
    "from decimal import Decimal\n",
    "print(sys.getsizeof(Decimal(1.0)))\n",
    "print(sys.getsizeof(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd07ea8-869c-47ec-906c-f48fe76c248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "alist = [a]\n",
    "sys.getsizeof(alist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e018ed23-a929-40df-b48d-ba240333a08c",
   "metadata": {},
   "source": [
    "Remember that empty `[]` itself takes up 56 bytes, so 64 - 56 = 8 bytes of new memory was added to the list `[]`. But since `a` is an integer, should it not take at least the minimum 28 bytes (one chunk filled) overhead shown above?\n",
    "\n",
    "It turns out the list doesn't contain the int objects themselves. It just contains an 8-byte pointer (size varies from system to system) to the actual int object. What that means is that the `getsizeof()` doesn't return the actual memory of the list and all the objects it contains, but only the memory of the list and the pointers to its objects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc43d4fe-2e81-4c3f-9bbb-32699b12e8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = \"BIOE 488\"\n",
    "c = 12345\n",
    "d = 10.1234\n",
    "blist = [a, b, c, d]\n",
    "sys.getsizeof(blist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af810527-273a-44e4-8909-350864f1bbf6",
   "metadata": {},
   "source": [
    "**[Exercise] How can you explain 88? Why does 88 not change irrespective of what type of data the list contains?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a14adbc-99e2-4324-9156-7de662411e4d",
   "metadata": {},
   "source": [
    "Answer:  ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9221b1b-270e-4e89-8207-395df0e4337e",
   "metadata": {},
   "source": [
    "### Memory addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2175058-3211-48ff-bbb3-3af320c247e8",
   "metadata": {},
   "source": [
    "Each object is stored in physical memory (RAM) at a particular address. How large an address is depends on the size of the physical memory of the system. The `id()` function returns the memory address of the input. We convert the output to the conventional hexadecimal system using `hex()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75561a25-be74-4c3f-ae18-813592e6201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81acdb7-ae8a-43d9-abac-d62f751e9560",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"address of b: \", hex(id(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57942f47-76ae-413c-b7ea-26917aa2576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"address of blist[3]: \", hex(id(blist[3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfbc5b8-f2bc-4bad-a7b0-22589d7a2bec",
   "metadata": {},
   "source": [
    "We can, in fact, verify the use of references seen in the above section by inspecting the memory addresses of variables and list elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6d8f4a-3de1-4d53-a164-4426938624f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember a\n",
    "print(a)\n",
    "print(\"address of a: \", hex(id(a)))\n",
    "print(\"address of a inside alist: \", hex(id(alist[0]))) #a\n",
    "print(\"address of a inside blist: \", hex(id(blist[0]))) #a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512030cd-e0ba-45c1-8e44-d6707e790b0d",
   "metadata": {},
   "source": [
    "This tells us that there is only one copy of `a` in memory and multiple objects simply point to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98b8448-4219-40af-9638-89181f617d5a",
   "metadata": {},
   "source": [
    "Read more - https://code.tutsplus.com/tutorials/understand-how-much-memory-your-python-objects-use--cms-25609"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efccaa8d-9892-4fcf-8dc1-d43864f165ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How we can recover the value given the address\n",
    "# Not easy as all memory is handled internally\n",
    "import ctypes\n",
    "print(id(b))\n",
    "b_recover = ctypes.cast(id(b), ctypes.py_object).value \n",
    "print(a_recover)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e9f8e0-521b-4e80-80f7-e96bfe901955",
   "metadata": {},
   "source": [
    "### References and reference counting\n",
    "\n",
    "Python automatically handles the allocation and deallocation of such objects. For immutable data types (ones which cannot be modified after creation), Python typically keeps a single unique copy in memory and makes multiple variables point to it i.e. \"reference\" it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df492539-98ba-4150-9e4c-616866c41db2",
   "metadata": {},
   "source": [
    "This is what `a = 100` looks like in memory (integers are immutable types):\n",
    "\n",
    "![Obj reference](./resources/object_reference.jpg)\n",
    "\n",
    "The integer object containing the value 100 has currently many references to it, including the user-defined variable `a`. We can check the total references to this object using `sys.getrefcount()`. Note that when calling `sys.getrefcount()`, the function's argument adds another reference to the object, thereby temporarily bumping up the object's reference count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c7bd04-ddaa-4e58-a901-e87311dbf105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "test_num = 100\n",
    "sys.getrefcount(test_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868182da-7950-4dc2-b9c0-a8b79a7abf3b",
   "metadata": {},
   "source": [
    "Why so many? The other references to the value `100` in memory are book-keeping variables used internally by Python/used in imported libraries and are not user-defined. Read more - https://groverlab.org/hnbfpr/2017-06-22-fun-with-sys-getrefcount.html\n",
    "\n",
    "Let's pick an object that's unlikely to be used internally (but we cannot guarantee this) so we can see more clearly what's going on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edddee52-bffb-4fcd-b83c-5024b0b96e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "immutable_number = -12345\n",
    "print(sys.getrefcount(immutable_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe417278-abc9-48f2-8a2a-f07b86674a6e",
   "metadata": {},
   "source": [
    "At this point, the value `-12345` has two references - 1) `immutable_number` variable, and 2) the call to `sys.getrefcount()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4e0e5e-1c98-426f-9339-5a612f7a42e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_numbers = immutable_number\n",
    "sys.getrefcount(immutable_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0d3300-fc6a-48b4-a81a-8bd5c09365c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [immutable_number, immutable_number, immutable_number]\n",
    "sys.getrefcount(immutable_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109891ee-6639-424f-bcfe-5f4b88b4153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del more_numbers\n",
    "print(sys.getrefcount(immutable_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cce048-98ae-45b5-b062-23c20897a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "del matrix\n",
    "sys.getrefcount(immutable_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdebd10-bdfc-4933-8e9a-504508a7a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "del immutable_number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ba9ee4-cffb-47db-9627-5c4725a057ed",
   "metadata": {},
   "source": [
    "At this point, the only reference to the object was deleted and its reference count likely went to zero. However, we cannot precisely predict reference counts at the user-level since observing will alter the reference count as there are several caching and optimization tricks that Python uses internally. Read more - https://www.csestack.org/python-getrefcount-reference-count-memory-management/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea25dc79-90fd-4577-b5a5-a42e7f4b06ec",
   "metadata": {},
   "source": [
    "### Garbage collection (GC)\n",
    "\n",
    "The Python memory manager will free up the space occupied by unused objects in memory through a process called \"garbage collection\". By default, Python offers automatic GC by means of reference counting. GC gets triggered as soon as the reference count of the object becomes 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff5e94a-e1ca-45d3-a076-416f2d5f3a4b",
   "metadata": {},
   "source": [
    "Notice that GC on the basis of reference count does not work if there are cyclic references. If an object is referencing itself or is part of a cyclic chain, the reference count of the array object will never become 0, and it will never be collected by the default reference counting GC.\n",
    "\n",
    "![](./resources/cyclic_reference.jpg)\n",
    "\n",
    "To free or reclaim the memory of the objects that have cyclic references, Python uses another GC algorithm that can be manually invoked/triggered using the `gc` module. Typically, this algorithm runs infrequently in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e146da-01af-40ca-ad9e-c9e1ad752425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import gc\n",
    "\n",
    "gc.disable()\n",
    "\n",
    "class PyObject(ctypes.Structure):\n",
    "    _fields_ = [('ob_refcnt', ctypes.c_ssize_t)]\n",
    "\n",
    "# create cyclic references\n",
    "obj_a, obj_b = {}, {}\n",
    "obj_a['next'], obj_b['next'] = obj_b, obj_a\n",
    "\n",
    "# save address of objects\n",
    "obj_a_addr, obj_b_addr = id(obj_a), id(obj_b)\n",
    "\n",
    "del obj_a, obj_b\n",
    "\n",
    "# proves that refcounts are not 0 due to cyclical reference\n",
    "print(f'obj_a refcount: {PyObject.from_address(obj_a_addr).ob_refcnt}')\n",
    "print(f'obj_b refcount: {PyObject.from_address(obj_b_addr).ob_refcnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d75ef4-ace5-418c-ab5c-9a15b05548b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(f'obj_a refcount: {PyObject.from_address(obj_a_addr).ob_refcnt}')\n",
    "print(f'obj_b refcount: {PyObject.from_address(obj_b_addr).ob_refcnt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d5b5f0-91c6-47da-abfb-254c5d9b7d1e",
   "metadata": {},
   "source": [
    "Read more about the `gc` module - https://docs.python.org/3/library/gc.html. \n",
    "\n",
    "Read more about GC generally - https://speakerdeck.com/pippolo84/an-insight-into-python-garbage-collection\n",
    "\n",
    "**General rule: Don’t change garbage collector behavior**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bbb323-6d82-41a5-bd3b-528949ce0946",
   "metadata": {},
   "source": [
    "----------------------\n",
    "# Monitoring memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8b64d2-e733-44cf-b993-98d1ef7a1de9",
   "metadata": {},
   "source": [
    "### Single lines of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9eef07-0e42-4256-8232-8b953a826072",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a106984-d014-4c56-bd0c-1fa47f6c4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/fabianp/memory_profiler\n",
    "%load_ext memory_profiler\n",
    "\n",
    "%memit a = list(range(20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea7295d-e9d2-44a3-83a5-b354d2acea0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cacc96f7-2d5a-4e04-9931-4f72da911a0c",
   "metadata": {},
   "source": [
    "Peak memory refers to the peak memory usage of your system (including memory usage of other processes) during the program runtime. Increment is the increment in memory usage relative to the memory usage just before the code is run (i.e. increment = peak memory - starting memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a90181-9237-45b9-be03-7b4eb2e16333",
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit a = [1] * (10 ** 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8c9f80-f2a5-4b60-9523-9bc07636e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit b = [2] * (2 * 10 ** 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393da5d2-48eb-4539-aeb0-69f7f3e8e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "memit_result = %memit -o b = [2] * (2 * 10 ** 7)\n",
    "print(\"stored in variable: \", memit_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ba9c12-9b37-44dc-8b44-032c5811bb3f",
   "metadata": {},
   "source": [
    "### One function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73daaaba-1177-4f21-bbf7-06f2fdb8b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# head over to functions.py..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a2584-cd5e-4cef-b4e3-a0ce910f6442",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mprof run functions.py\n",
    "!mprof plot -o my_func.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053da86-2302-48cf-a70b-8060f06ab846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect memory_profiler.log and my_func.png..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58af94c2-cda2-4a17-893b-3da79fa445b3",
   "metadata": {},
   "source": [
    "For profiling full scripts, you can modify main() in function.py to run all the functions in the script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cddf41-35e3-4b82-8184-3fb27da3bb0f",
   "metadata": {},
   "source": [
    "----------------\n",
    "# Handling memory-related issues - Memory Mapping for file I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9ffe2f-9c5a-44d9-9345-675694d28dda",
   "metadata": {},
   "source": [
    "Memory mapping uses lower-level operating system APIs to store file contents directly in physical memory. This approach often results in improved I/O performance because it avoids many costly system calls and reduces expensive data buffer transfers.\n",
    "\n",
    "![](./resources/fileio_read.jpg)\n",
    "\n",
    "Numpy arrays have built-in support for memory mapping.\n",
    "\n",
    "![](./resources/numpy_memmap.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f800d728-0467-43dd-a359-f4d9ce0e1e66",
   "metadata": {},
   "source": [
    "### Scenario - File too large to load into RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748fe873-d554-4bff-9050-8afdbf4e73b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a random data array\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "num_arr = np.random.rand(50000, 2000)\n",
    "print(sys.getsizeof(num_arr))\n",
    "\n",
    "# store it to disk and remove from memory - takes upto 10s!\n",
    "np.save('big_data.npy', num_arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a1c910-31d8-45b2-848d-c53c28777b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ~800Mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a6cec9-dc67-4ea5-875d-e31338dbaf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_something(data):\n",
    "    random_int = np.random.randint(low=10, high=10000)\n",
    "    result = np.mean((2 * np.log(data[:random_int])) + data[-random_int:])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062248d7-7bf6-484f-ba9e-460f2aecea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_something(num_arr))\n",
    "del num_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c23308-0266-4db2-9d7d-7e55d987b15e",
   "metadata": {},
   "source": [
    "### Solution - Reading NumPy arrays using memory mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc22c1d-fa50-4e8b-8066-ddc7c68e778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exercise\n",
    "#print(compute_something() --> Load\n",
    "#print(compute_something() --> memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb068e5a-a41e-4f05-bb2a-02a3dec35c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext memory_profiler\n",
    "\n",
    "# Exercise:\n",
    "def repeat_compute_normal(n_repeats=10):\n",
    "    results = []\n",
    "    return results\n",
    "\n",
    "# Exercise:\n",
    "def repeat_compute_memmap(n_repeats=10):\n",
    "    results = []\n",
    "    return results\n",
    "\n",
    "def parse_increments(results):\n",
    "    increments = []\n",
    "    for i in range(len(results)):\n",
    "        value = float(str(results[i]).split('increment: ')[1].split(' MiB')[0])\n",
    "        increments.append(value)\n",
    "    return increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a772a5-490a-48ed-9087-779a2854afb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no memory mapping - reading the file entirely may not always be possible depending on how large of RAM you have.\n",
    "increments_normal = parse_increments(repeat_compute_normal())\n",
    "\n",
    "print(\"-------\")\n",
    "\n",
    "# with memory mapping\n",
    "increments_memmap = parse_increments(repeat_compute_memmap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55471914-b14d-4e3b-8d0e-a94fa8bc5981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot increments over time\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(increments_normal,'g*-', label='normal')\n",
    "plt.plot(increments_memmap, 'ro-', label='memmap')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Varying data sizes (unordered)\", fontsize=16)\n",
    "plt.xticks([])\n",
    "plt.ylabel(\"Incremental memory (MiB)\", fontsize=16)\n",
    "#plt.ylim(0,1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e81bb4-529e-480c-9e85-5a9ec8ce919c",
   "metadata": {},
   "source": [
    "Notice how the same function call using the same input data yielded vastly different memory usage. Numpy's memory mapping is especially useful when only smaller portions of the array are needed at any given time and not the full array. Read more - https://pythonspeed.com/articles/mmap-vs-zarr-hdf5/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a65701-1501-4a0f-bce1-6eb262b22c47",
   "metadata": {},
   "source": [
    "In general, memory mapping is another way to perform file I/O that can result in better performance and memory efficiency. For Python's native API, read https://docs.python.org/3/library/mmap.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab401db-a7a6-44cb-a1a9-04910e4e7168",
   "metadata": {},
   "source": [
    "You are likely to encounter memory issues primarily due to two reasons: 1) either your computational procedure/algorithm requires too much space to compute the result (example - creating too many temporary intermediate variables or data structures) or it needs to use data contained in very large files (example - loading a dataset of 10,000 medical images).\n",
    "\n",
    "Despite the simplicity in how memory leaks/issues emerge, there is no one-size-fits-all strategy to handling large files or computations. Nonetheless, a useful first exercise is to characterize your problem along the following dimensions:\n",
    "- **Compute patterns**\n",
    "    - Can I re-use intermediate results from previous iterations in the current iteration of the algorithm?\n",
    "    - Can I re-define my algorithm to use a different and more efficient data structure?\n",
    "    - How long do I need to keep a particular variable alive in the program?\n",
    "    - How exact a result do I need? In other words, can you tolerate an approximate result that is far easier to compute?\n",
    "    - Are there language-specific optimizations you could do?\n",
    "    - Does my program use concurrency or parallelism to read the same data?\n",
    "- **Data access patterns**\n",
    "    - How much of the data in the file do I need to use at any given time? All of it or smaller portions of it?\n",
    "    - How frequently do I need the data? Does it need to be always available to use?\n",
    "    - Read vs. write? Do I want to over-write the data or only read it?\n",
    "    - Do I want multiple programs to read/write to the same file?\n",
    "- **Storage options**\n",
    "    - In what type of physical/network storage can the file be best stored?\n",
    "    - Does the numerical data format used accurately and efficiently represent the information contained in the data? \n",
    "    - Can I effectively compress the data without losing the information I need?\n",
    "    - Would storing the data in a database help?\n",
    "- **Memory and compute trade-offs / space-time trade-offs**\n",
    "    - Would computing a quantity on-the-fly be more efficient than reading it from a file?\n",
    "    \n",
    "    \n",
    "We may be able to build a strategy that fits our needs and constraints by thinking about questions like these. Although throwing money at the problem is always an available option, i.e., buying more/better compute and storage hardware, it is best to consider it as a last resort. As unbelievable as it may sound, the Apollo Guidance Computer used in NASA's Apollo 11 space mission in fact \"....only had 32,768 bits of Random Access Memory and only 72KB of Read-Only Memory....\" - https://interestingengineering.com/innovation/in-defense-of-the-apollo-programs-guidance-computer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a0a78-2ef2-4b71-8e1f-aa51ff324c3c",
   "metadata": {},
   "source": [
    "# Delete all files that are not needed for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a1349-5b67-487d-a480-3976fa6e7ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm big_data.npy\n",
    "!rm mprofile_*.dat\n",
    "!rm *.log\n",
    "!rm my_func.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3a82e0-9a34-4e43-b919-397ff033735b",
   "metadata": {},
   "source": [
    "---------------\n",
    "--------------\n",
    "## Ensure only relevant files are tracked when submitting this lab!\n",
    "--------------\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5538990e-6a43-468f-b25b-6cac261770aa",
   "metadata": {},
   "source": [
    "### References:\n",
    "- https://www.honeybadger.io/blog/memory-management-in-python/\n",
    "- https://www.cs.swarthmore.edu/~kwebb/cs31/f18/memhierarchy/mem_hierarchy.html\n",
    "- https://realpython.com/python-mmap/\n",
    "- https://fa.bianp.net/blog/2014/plot-memory-usage-as-a-function-of-time/\n",
    "- https://pythonspeed.com/articles/mmap-vs-zarr-hdf5/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
